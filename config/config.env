# APEGA Configuration
# AI Models
OPENAI_API_KEY=your-openai-api-key
GOOGLE_API_KEY=your-google-api-key

# Model names
QA_MODEL=o4-mini
EMBEDDING_MODEL=text-embedding-3-large
GENERATION_MODEL=gemini-2.5-pro-preview-05-06
PROMPT_ENGINEERING_MODEL=o4-mini

# Vector Database (Qdrant)
QDRANT_URL=http://localhost:6333  # Update if using cloud deployment
QDRANT_API_KEY=  # Required only for cloud deployment
QDRANT_COLLECTION_NAME=clp_knowledge
VECTOR_DIMENSIONS=3072  # Native dimensionality of text-embedding-3-large

# Document Processing
CHUNK_SIZE_TOKENS=1024  # Maximum tokens per chunk
CHUNK_OVERLAP_TOKENS=200  # Overlap between chunks
CHUNKING_STRATEGY=hybrid_hierarchical_semantic  # Strategy for text chunking

# RAG Parameters
TOP_K_DENSE=10  # Initial results from dense vector search
TOP_K_SPARSE=10  # Initial results from sparse keyword search
TOP_K_RERANK=5  # Results to keep after reranking

# API Rate Limiting
MAX_API_RETRIES=5  # Maximum retry attempts for API calls

# Logging
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# Paths
SOURCE_DOCUMENTS_DIR=/Users/logan/Git/Agents/APEGA/Context
OUTPUT_DIR=/Users/logan/Git/Agents/APEGA/output
TEMPLATES_DIR=/Users/logan/Git/Agents/APEGA/templates

# QA Settings
MAX_QA_RETRIES=2  # Maximum attempts to refine a question after QA feedback